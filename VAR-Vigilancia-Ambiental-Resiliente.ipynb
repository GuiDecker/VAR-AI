{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNuV+IYu1UaQPgVqLfxO6Fx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GuiDecker/VAR-AI/blob/main/VAR-Vigilancia-Ambiental-Resiliente.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DaBnHXuqMXim"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q google-generativeai\n",
        "!pip install -U -q ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "WKs12835Mfxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Dataset treinado YOLO versão 8.***\n",
        "  Faça o upload do arquivo .pt (Disponivel no repositório do github)\n",
        "\n",
        "  EXEMPLO:\n",
        "\n",
        "\n",
        "```\n",
        "model = YOLO(\"/content/yolov8n.pt\")\n",
        "\n",
        " model.predict(source=\"/content/areas-de-risco.jpeg\", conf=0.7, save=True, show=True)\n",
        "```"
      ],
      "metadata": {
        "id": "ggUonyLjMhV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# EXEMPLO: model = YOLO(\"/content/yolov8n.pt\")\n",
        "model = YOLO(\"<ARQUIVO_YOLO_AQUI>\")\n",
        "\n",
        "# Irá fazer a detecção de pessoas, animais, objetos utilizando visão computacional\n",
        "\n",
        "model.predict(source=\"<CAMINHO_ARQUIVO_AQUI>\", conf=0.7, save=True, show=True)\n",
        "#EXEMPLO:  model.predict(source=\"/content/areas-de-risco.jpeg\", conf=0.7, save=True, show=True)"
      ],
      "metadata": {
        "id": "EA8N2mjkMk1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extração de frames do arquivo\n",
        "\n",
        "Como o Gemini nâo aceita arquivos de vídeos diretamente, é necessario quebar o vídeo em multiplas frames de imagens de 1 segundo\n",
        "\n",
        "Você pode colocar um arquivo local ou uma url que contenha algum arquivo de imagem ou vídeo"
      ],
      "metadata": {
        "id": "dEklVzSeOfVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "# O vídeo comentádo de 10min é um vídeo padrão do sherlock homes, caso queira testa-lo também, sugiro passar a variavél full_video como False\n",
        "# video_file_name = \"https://storage.googleapis.com/generativeai-downloads/data/SherlockJr._10min.mp4\"\n",
        "\n",
        "# Vídeo local de desastre ambiental das enchentes no Rio Grande do Sul\n",
        "video_file_name = \"/content/runs/detect/predict/RS_video.avi\"\n",
        "\n",
        "\n",
        "# Crie ou limpe o diretório de frames de imagens extraídos existente.\n",
        "FRAME_EXTRACTION_DIRECTORY = \"/content/frames\"\n",
        "FRAME_PREFIX = \"_frame\"\n",
        "def create_frame_output_dir(output_dir):\n",
        "  if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "  else:\n",
        "    shutil.rmtree(output_dir)\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "def extract_frame_from_video(video_file_path):\n",
        "  print(f\"Extraindo {video_file_path} a 1 quadro por segundo. pode levar um tempo...\")\n",
        "  create_frame_output_dir(FRAME_EXTRACTION_DIRECTORY)\n",
        "  vidcap = cv2.VideoCapture(video_file_path)\n",
        "  fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
        "  frame_duration = 1 / fps # Intervalo de tempo entre frames (em segundos)\n",
        "  output_file_prefix = os.path.basename(video_file_path).replace('.', '_')\n",
        "  frame_count = 0\n",
        "  count = 0\n",
        "  while vidcap.isOpened():\n",
        "      success, frame = vidcap.read()\n",
        "      if not success: # Final do video\n",
        "          break\n",
        "      if int(count / fps) == frame_count: # Extrai um frame a cada segundo\n",
        "          min = frame_count // 60\n",
        "          sec = frame_count % 60\n",
        "          time_string = f\"{min:02d}:{sec:02d}\"\n",
        "          image_name = f\"{output_file_prefix}{FRAME_PREFIX}{time_string}.jpg\"\n",
        "          output_filename = os.path.join(FRAME_EXTRACTION_DIRECTORY, image_name)\n",
        "          cv2.imwrite(output_filename, frame)\n",
        "          frame_count += 1\n",
        "      count += 1\n",
        "  vidcap.release()\n",
        "  print(f\"Extração de frames de vídeo concluída!\\n\\Extraído: {frame_count} frames\")\n",
        "\n",
        "extract_frame_from_video(video_file_name)"
      ],
      "metadata": {
        "id": "VwLRqolrNJ2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Upload de frames usando o File API**\n",
        "\n",
        "Depois de extrair, faça o upload da captura dos frames tiradas do arquivo da variavel **video_file_name**\n",
        "\n",
        "File API aceita arquivos abaixo de 2GB e pode armazenar até 20GB de arquivos por projeto."
      ],
      "metadata": {
        "id": "0Ky46mC1Nq62"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XqLcDYU8N8nW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "\n",
        "class File:\n",
        "  def __init__(self, file_path: str, display_name: str = None):\n",
        "    self.file_path = file_path\n",
        "    if display_name:\n",
        "      self.display_name = display_name\n",
        "    self.timestamp = get_timestamp(file_path)\n",
        "\n",
        "  def set_file_response(self, response):\n",
        "    self.response = response\n",
        "\n",
        "def get_timestamp(filename):\n",
        "  \"\"\"Extrai a contagem de Frames (como um número inteiro) de um nome de arquivo com o formato\n",
        "     'output_file_prefix_frame00:00.jpg'.\n",
        "  \"\"\"\n",
        "  parts = filename.split(FRAME_PREFIX)\n",
        "  if len(parts) != 2:\n",
        "      return None  # Indica que o nome do arquivo pode estar formatado incorretamente\n",
        "  return parts[1].split('.')[0]\n",
        "\n",
        "# Processa cada Frame do vídeo no diretório de saída\n",
        "files = os.listdir(FRAME_EXTRACTION_DIRECTORY)\n",
        "files = sorted(files)\n",
        "files_to_upload = []\n",
        "for file in files:\n",
        "  files_to_upload.append(\n",
        "      File(file_path=os.path.join(FRAME_EXTRACTION_DIRECTORY, file)))\n",
        "\n",
        "#Enviar os arquivos para a API\n",
        "# Carregando apenas uma parte teste de 10 segundos de arquivos para reduzir o tempo de upload.\n",
        "# Altere full_video para True para enviar o vídeo inteiro e False para reduzido.\n",
        "full_video = True\n",
        "\n",
        "uploaded_files = []\n",
        "print(f'Uploading {len(files_to_upload) if full_video else 10} files. Isso pode levar um tempo...')\n",
        "\n",
        "for file in files_to_upload if full_video else files_to_upload[40:50]:\n",
        "  print(f'Uploading: {file.file_path}...')\n",
        "  response = genai.upload_file(path=file.file_path)\n",
        "  file.set_file_response(response)\n",
        "  uploaded_files.append(file)\n",
        "\n",
        "print(f\"Uploads de arquivos concluídos!\\n\\nUploaded: {len(uploaded_files)} files\")\n"
      ],
      "metadata": {
        "id": "N2jGrCzmNJ12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lista os arquivos enviados na API\\**\n",
        "\n",
        "Verificação para ver se os arquivos foram publicados com sucesso no File API"
      ],
      "metadata": {
        "id": "UBEpkEGpNRAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista os arquivos enviados na API\n",
        "for n, f in zip(range(len(uploaded_files)), genai.list_files()):\n",
        "  print(f.uri)"
      ],
      "metadata": {
        "id": "YalpWEY8NOSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Geração e analise do conteúdo com genai**"
      ],
      "metadata": {
        "id": "6airDoWcNVif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criação prompt.\n",
        "prompt = \"Analise o vídeo cheque se o ambiente se passa em algum desastre, acidente ou confusão. E se tiver acontecido alguma enchente, fogo, terremoto, destruição de coisas, faça um passo a passo preciso de ações especificas para ajudar as pessoas dependendo da condição do ambiente, e também traga ações imeditas dependendo do tipo de pessoa, seja ela criança ou idosa ou animal. E principalmente analise se tem qualquer sinal de pessoas e descreva como e onde essa pessoa estava no vídeo, levantando descrições de ações de resgate para autoridades.\"\n",
        "\n",
        "model = genai.GenerativeModel(model_name=\"models/gemini-1.5-pro-latest\")\n",
        "\n",
        "# Faça a solicitação GenerateContent com a estrutura descrita acima.\n",
        "def make_request(prompt, files):\n",
        "  request = [prompt]\n",
        "  for file in files:\n",
        "    request.append(file.timestamp)\n",
        "    request.append(file.response)\n",
        "  return request\n",
        "\n",
        "# Execução da solicitação LLM.\n",
        "request = make_request(prompt, uploaded_files)\n",
        "response = model.generate_content(request,\n",
        "                                  request_options={\"timeout\": 600})\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "-gtfU4uWNPqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deletar Arquivos que publicados na API, caso queira liberar espaço**"
      ],
      "metadata": {
        "id": "YQ33mKKpP8oj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Deleting {len(uploaded_files)} images. This might take a bit...')\n",
        "for file in uploaded_files:\n",
        "  genai.delete_file(file.response.name)\n",
        "  print(f'Deleted {file.file_path} at URI {file.response.uri}')\n",
        "print(f\"Completed deleting files!\\n\\nDeleted: {len(uploaded_files)} files\")"
      ],
      "metadata": {
        "id": "LKANLbUmQMdM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}